{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-18T07:16:57.651438Z",
     "iopub.status.busy": "2025-07-18T07:16:57.650863Z",
     "iopub.status.idle": "2025-07-18T07:16:57.667476Z",
     "shell.execute_reply": "2025-07-18T07:16:57.666475Z",
     "shell.execute_reply.started": "2025-07-18T07:16:57.651413Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tesla-complete-stocks-dataset/TSLA_2019-01-30_2025-04-17.csv\n",
      "/kaggle/input/tesla-complete-stocks-dataset/TSLA_2019-01-30_2025-07-14.csv\n",
      "/kaggle/input/tesla-complete-stocks-dataset/TSLA_2019-01-30_2025-05-12.csv\n",
      "/kaggle/input/tesla-complete-stocks-dataset/TSLA_2019-01-30_2025-04-06.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:17:38.505582Z",
     "iopub.status.busy": "2025-07-18T07:17:38.505022Z",
     "iopub.status.idle": "2025-07-18T07:17:38.509367Z",
     "shell.execute_reply": "2025-07-18T07:17:38.508459Z",
     "shell.execute_reply.started": "2025-07-18T07:17:38.505557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #suppress warnings in outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:30:07.541499Z",
     "iopub.status.busy": "2025-07-18T07:30:07.541220Z",
     "iopub.status.idle": "2025-07-18T07:30:07.574587Z",
     "shell.execute_reply": "2025-07-18T07:30:07.573816Z",
     "shell.execute_reply.started": "2025-07-18T07:30:07.541478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is: (1621, 7)\n",
      "\n",
      "Index(['date', 'open', 'high', 'low', 'close', 'adj_close', 'volume'], dtype='object')\n",
      "\n",
      " date         object\n",
      "open         object\n",
      "high         object\n",
      "low          object\n",
      "close        object\n",
      "adj_close    object\n",
      "volume       object\n",
      "dtype: object \n",
      "\n",
      "         date                open                high                 low  \\\n",
      "1  2019-01-30  20.030000686645508  20.600000381469727   19.89933204650879   \n",
      "2  2019-01-31  20.066667556762695  20.770666122436523  19.600000381469727   \n",
      "3  2019-02-01    20.3613338470459  21.073333740234375  20.233333587646484   \n",
      "\n",
      "                close           adj_close     volume  \n",
      "1  20.584667205810547  20.584667205810547  168754500  \n",
      "2  20.468000411987305  20.468000411987305  188538000  \n",
      "3   20.81399917602539   20.81399917602539  109251000   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>297.54998779296875</td>\n",
       "      <td>300.1499938964844</td>\n",
       "      <td>293.54998779296875</td>\n",
       "      <td>295.8800048828125</td>\n",
       "      <td>295.8800048828125</td>\n",
       "      <td>75586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>300.04998779296875</td>\n",
       "      <td>310.4800109863281</td>\n",
       "      <td>300.0</td>\n",
       "      <td>309.8699951171875</td>\n",
       "      <td>309.8699951171875</td>\n",
       "      <td>104365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>307.8900146484375</td>\n",
       "      <td>314.0899963378906</td>\n",
       "      <td>305.6499938964844</td>\n",
       "      <td>313.510009765625</td>\n",
       "      <td>313.510009765625</td>\n",
       "      <td>78921900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                open               high                 low  \\\n",
       "1619  2025-07-09  297.54998779296875  300.1499938964844  293.54998779296875   \n",
       "1620  2025-07-10  300.04998779296875  310.4800109863281               300.0   \n",
       "1621  2025-07-11   307.8900146484375  314.0899963378906   305.6499938964844   \n",
       "\n",
       "                  close          adj_close     volume  \n",
       "1619  295.8800048828125  295.8800048828125   75586800  \n",
       "1620  309.8699951171875  309.8699951171875  104365300  \n",
       "1621   313.510009765625   313.510009765625   78921900  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#data = pd.read_csv(\"../input/s-and-p-500-spy/spy.csv\")\n",
    "data = pd.read_csv(\"../input/tesla-complete-stocks-dataset/TSLA_2019-01-30_2025-07-14.csv\") #up to 14/Jul/25\n",
    "#exclude the 1st redundant row in TSLA\n",
    "data = data[1:]\n",
    "\n",
    "print(f\"The shape of the data is: {data.shape}\\n\")\n",
    "print(data.columns)\n",
    "print(f\"\\n {data.dtypes} \\n\")\n",
    "print(f\"{data.head(3)} \\n\")\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:30:19.872237Z",
     "iopub.status.busy": "2025-07-18T07:30:19.871527Z",
     "iopub.status.idle": "2025-07-18T07:30:19.879037Z",
     "shell.execute_reply": "2025-07-18T07:30:19.878101Z",
     "shell.execute_reply.started": "2025-07-18T07:30:19.872208Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check any null: False\n",
      "check any NaN: False\n"
     ]
    }
   ],
   "source": [
    "#null/nan check \n",
    "print(f\"check any null: {data.isnull().any().any()}\")\n",
    "print(f\"check any NaN: {data.isna().any().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T08:00:34.848384Z",
     "iopub.status.busy": "2025-07-18T08:00:34.847666Z",
     "iopub.status.idle": "2025-07-18T08:00:34.860116Z",
     "shell.execute_reply": "2025-07-18T08:00:34.859252Z",
     "shell.execute_reply.started": "2025-07-18T08:00:34.848355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-numeric values in open: 1621\n",
      "Total number of non-numeric values in high: 1621\n",
      "Total number of non-numeric values in low: 1621\n",
      "Total number of non-numeric values in close: 1621\n",
      "Total number of non-numeric values in adj_close: 1621\n",
      "Total number of non-numeric values in volume: 1621\n"
     ]
    }
   ],
   "source": [
    "#numeric cols are all non-numerics\n",
    "for col in ['open', 'high', 'low', 'close', 'adj_close', 'volume']:\n",
    "    non_numeric = data[col][~data[col].apply(lambda x: isinstance(x, (int, float)))]\n",
    "    if not non_numeric.empty:\n",
    "        print(f\"Total number of non-numeric values in {col}: {len(non_numeric)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T08:36:12.847125Z",
     "iopub.status.busy": "2025-07-18T08:36:12.846397Z",
     "iopub.status.idle": "2025-07-18T08:36:12.869730Z",
     "shell.execute_reply": "2025-07-18T08:36:12.869014Z",
     "shell.execute_reply.started": "2025-07-18T08:36:12.847093Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>2.997231</td>\n",
       "      <td>3.025291</td>\n",
       "      <td>2.990686</td>\n",
       "      <td>3.024546</td>\n",
       "      <td>3.024546</td>\n",
       "      <td>18.943956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>2.999060</td>\n",
       "      <td>3.033542</td>\n",
       "      <td>2.975530</td>\n",
       "      <td>3.018863</td>\n",
       "      <td>3.018863</td>\n",
       "      <td>19.054810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>3.013638</td>\n",
       "      <td>3.048008</td>\n",
       "      <td>3.007331</td>\n",
       "      <td>3.035626</td>\n",
       "      <td>3.035626</td>\n",
       "      <td>18.509159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      open      high       low     close  adj_close     volume\n",
       "1  2019-01-30  2.997231  3.025291  2.990686  3.024546   3.024546  18.943956\n",
       "2  2019-01-31  2.999060  3.033542  2.975530  3.018863   3.018863  19.054810\n",
       "3  2019-02-01  3.013638  3.048008  3.007331  3.035626   3.035626  18.509159"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log the numerical columns: OHLC, adj_close, vol\n",
    "#turn original str to float fist\n",
    "num_cols = ['open', 'high', 'low', 'close', 'adj_close', 'volume']\n",
    "data[num_cols] = data[num_cols].apply(pd.to_numeric).apply(np.log)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T08:38:48.637030Z",
     "iopub.status.busy": "2025-07-18T08:38:48.636423Z",
     "iopub.status.idle": "2025-07-18T08:38:48.644030Z",
     "shell.execute_reply": "2025-07-18T08:38:48.643193Z",
     "shell.execute_reply.started": "2025-07-18T08:38:48.637005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check any null: False\n",
      "check any NaN: False\n"
     ]
    }
   ],
   "source": [
    "#null/nan check \n",
    "print(f\"check any null: {data.isnull().any().any()}\")\n",
    "print(f\"check any NaN: {data.isna().any().any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T08:39:56.398707Z",
     "iopub.status.busy": "2025-07-18T08:39:56.398434Z",
     "iopub.status.idle": "2025-07-18T08:39:56.424571Z",
     "shell.execute_reply": "2025-07-18T08:39:56.423847Z",
     "shell.execute_reply.started": "2025-07-18T08:39:56.398686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1621.000000</td>\n",
       "      <td>1621.000000</td>\n",
       "      <td>1621.000000</td>\n",
       "      <td>1621.000000</td>\n",
       "      <td>1621.000000</td>\n",
       "      <td>1621.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.945473</td>\n",
       "      <td>4.968008</td>\n",
       "      <td>4.921445</td>\n",
       "      <td>4.945682</td>\n",
       "      <td>4.945682</td>\n",
       "      <td>18.517814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.993279</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>0.991665</td>\n",
       "      <td>0.992571</td>\n",
       "      <td>0.992571</td>\n",
       "      <td>0.494865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.490999</td>\n",
       "      <td>2.521346</td>\n",
       "      <td>2.468043</td>\n",
       "      <td>2.479168</td>\n",
       "      <td>2.479168</td>\n",
       "      <td>17.196566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.804758</td>\n",
       "      <td>4.835885</td>\n",
       "      <td>4.785406</td>\n",
       "      <td>4.813971</td>\n",
       "      <td>4.813971</td>\n",
       "      <td>18.179340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.371103</td>\n",
       "      <td>5.390441</td>\n",
       "      <td>5.344485</td>\n",
       "      <td>5.370095</td>\n",
       "      <td>5.370095</td>\n",
       "      <td>18.459242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.562987</td>\n",
       "      <td>5.587548</td>\n",
       "      <td>5.546466</td>\n",
       "      <td>5.567466</td>\n",
       "      <td>5.567466</td>\n",
       "      <td>18.802447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.165208</td>\n",
       "      <td>6.191421</td>\n",
       "      <td>6.125799</td>\n",
       "      <td>6.173494</td>\n",
       "      <td>6.173494</td>\n",
       "      <td>20.633431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open         high          low        close    adj_close  \\\n",
       "count  1621.000000  1621.000000  1621.000000  1621.000000  1621.000000   \n",
       "mean      4.945473     4.968008     4.921445     4.945682     4.945682   \n",
       "std       0.993279     0.993915     0.991665     0.992571     0.992571   \n",
       "min       2.490999     2.521346     2.468043     2.479168     2.479168   \n",
       "25%       4.804758     4.835885     4.785406     4.813971     4.813971   \n",
       "50%       5.371103     5.390441     5.344485     5.370095     5.370095   \n",
       "75%       5.562987     5.587548     5.546466     5.567466     5.567466   \n",
       "max       6.165208     6.191421     6.125799     6.173494     6.173494   \n",
       "\n",
       "            volume  \n",
       "count  1621.000000  \n",
       "mean     18.517814  \n",
       "std       0.494865  \n",
       "min      17.196566  \n",
       "25%      18.179340  \n",
       "50%      18.459242  \n",
       "75%      18.802447  \n",
       "max      20.633431  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T09:03:32.722930Z",
     "iopub.status.busy": "2025-07-18T09:03:32.722612Z",
     "iopub.status.idle": "2025-07-18T09:03:33.013110Z",
     "shell.execute_reply": "2025-07-18T09:03:33.012262Z",
     "shell.execute_reply.started": "2025-07-18T09:03:32.722885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from matplotlib.dates import DateFormatter, QuarterLocator\n",
    "#plot the \"adj_close\" with time\n",
    "# Convert 'time' column from string to datetime\n",
    "\n",
    "#data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))  # Set figure size\n",
    "plt.plot(data['date'], data['adj_close'], linestyle='-', color='b', label='log adj_close') #kwarg \"marker='o'\" will add data points on the line\n",
    "\n",
    "# Set x-axis to show quarterly frequency\n",
    "ax = plt.gca()  # Get current axis\n",
    "#ax.xaxis.set_major_locator(QuarterLocator())  # Quarterly intervals\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))  # Format as YYYY-MM\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Time in daily')\n",
    "plt.ylabel('adj_close in Log')\n",
    "plt.title('TSLA log adj_close')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#only pick the \"date\", \"adj_close\" for model building/testing\n",
    "data_adj = data[[\"date\", \"adj_close\"]]\n",
    "\n",
    "#use the log difference to represent 1-d return as a new column \"adj_r\"\n",
    "data_adj[\"adj_r\"] = data_adj[\"adj_close\"].diff()\n",
    "\n",
    "#use cluster method for z-scores\n",
    "# Define cluster size\n",
    "cluster_size = 20\n",
    "\n",
    "# Add \"cluster\" col\n",
    "df['cluster'] = df.index // cluster_size\n",
    "\n",
    "# Compute mean and std for each cluster\n",
    "cluster_stats = df.groupby('cluster')['adj_r'].agg(['mean', 'std']).shift(1)  # Shift to move i-1 cluster's stats for the i cluster\n",
    "\n",
    "# Initialise \"z_score\" column\n",
    "df['z_score'] = np.nan\n",
    "\n",
    "# Compute Z-scores using previous cluster's mean and std\n",
    "for cluster_id, group in df.groupby('cluster'):\n",
    "    if cluster_id > 0:  # Skip first cluster\n",
    "        mean_prev = cluster_stats.loc[cluster_id, 'mean']\n",
    "        std_prev = cluster_stats.loc[cluster_id, 'std']\n",
    "        if not np.isnan(std_prev) and std_prev != 0:\n",
    "            df.loc[group.index, 'z_score'] = (group['price_diff'] - mean_prev) / std_prev\n",
    "        else:\n",
    "            df.loc[group.index, 'z_score'] = 0  # Handle zero std or NaN\n",
    "\n",
    "# Optional: Handle NaN values\n",
    "# df['z_score'] = df['z_score'].fillna(0)\n",
    "\n",
    "#check any 0 and NaN in the result \"z_score\" col\n",
    "z_nans = df['z_score'].isna().sum() #shouldn't be > cluster size number of \"NaN\"\n",
    "z_zeros = (df['z_score'] == 0).sum()\n",
    "print(f\"Total number of NaN values in z_score: {z_nans}\")\n",
    "print(f\"Total number of zeros in z_score: {z_zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import polars as pl #replace the pd for performance\n",
    "import numpy as np\n",
    "import math\n",
    "import inspect\n",
    "import random\n",
    "import psutil\n",
    "import logging\n",
    "import gc\n",
    "from collections import namedtuple, deque\n",
    "from typing import Tuple, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_forecasting.models.nn import MultiEmbedding\n",
    "\"\"\"\n",
    "input data is in dataframe = {\n",
    "    \"timedate\" : [],\n",
    "    \"raw_price\" : [],\n",
    "    \"log_daily_return\" : [],\n",
    "    \"feature_n\" : [], \n",
    "    \"...\" : [],\n",
    "}\n",
    "\n",
    "! for multi assets, the input data is expected to be in >=3D, so the corresponding function should be adjusted for taking the >=3D dataset. \n",
    "\"\"\"\n",
    "def col2idx(dataframe):\n",
    "        #save the column names for future column selection use after the data is converted into tensor\n",
    "        column_names = dataframe.columns.tolist()\n",
    "        col2idx = {name: i for i, name in enumerate(column_names)}\n",
    "    return col2idx\n",
    "\n",
    "class DataSampler(Dataset):\n",
    "    \"\"\"Dataset that generates random sequences for MDP training\"\"\"\n",
    "    def __init__(self, dataframe, sample_length: int, epoch_size: int=10000):\n",
    "        self.dataframe = dataframe\n",
    "        self.sample_length = sample_length #input_len + holding_len, default assumption input_len = holding_len\n",
    "        self.epoch_size=epoch_size\n",
    "        self.max_start_idx = len(dataframe) - sample_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(self.epoch_size, self.max_start_idx)\n",
    "    \n",
    "    def __getitem__(self, idx): #to enable the `[]` accessor\n",
    "        start_idx = random.randint(0, self.max_start_idx) #has overlapping effects\n",
    "        end_idx = start_idx + self.sample_length\n",
    "        sample_sequence = self.dataframe.iloc[start_idx:end_idx].values #2D\n",
    "        #keep an independant dataframe result by `.copy()`, otherwise use `.values` to get np.ndarray\n",
    "\n",
    "        return torch.FloatTensor(sample_sequence) \n",
    "\n",
    "    def get_batch(self, batch_size): #the `batch_size` is expected to be <= `len(training_set)`\n",
    "        \"\"\"Get a single batch of samples\"\"\"\n",
    "        batch_samples = []\n",
    "        for _ in range(batch_size):\n",
    "            # Get random sample (idx parameter is ignored because of `__getitem__`)\n",
    "            sample = self[0]  # idx doesn't matter\n",
    "            batch_samples.append(sample)\n",
    "        return torch.stack(batch_samples, dim=0)\n",
    "    \n",
    "    def batch_generator(self, batch_size, num_batches=None):\n",
    "        \"\"\"Generator that yields batches indefinitely or for specified number\"\"\"\n",
    "        count = 0\n",
    "        while num_batches is None or count < num_batches:\n",
    "            yield self.get_batch(batch_size)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Env2D: #can only handle <=2D states, single asset mode\n",
    "    \"\"\"Custom MDP Environment using sample_sequences from a sample_batch\"\"\"\n",
    "    def __init__(self, col_idx: dict[str, int], price_col_name: str =\"adj_close\", \n",
    "                 trade_principal: int = 100000, fee_rate: float = 0.01, \n",
    "                 eval_mode: bool = False): \n",
    "        \"\"\"\n",
    "        Initialize MDP environment by iterate `sample_sequences` from the batch out of the `DataSampler`\n",
    "        \n",
    "        Args:\n",
    "            sample_sequence: tensor.shape = (T, E)\n",
    "            reward_function: function assumes each sequence contains a pair of S_{t} and S_{t+1}, \n",
    "                    so the any of the len(s_{t}) would be tau = T_even / 2, or (T_odd +1) / 2, where T_even is preferred. \n",
    "        \"\"\"       \n",
    "        self.trade_principal = trade_principal\n",
    "        self.fee_rate = fee_rate\n",
    "        self.eval_mode = eval_mode\n",
    "\n",
    "        # Store defaults and set attributes\n",
    "        self._defaults = dict(\n",
    "            trade_principal=trade_principal,\n",
    "            fee_rate=fee_rate,\n",
    "            eval_mode=eval_mode\n",
    "        )\n",
    "            \n",
    "    @classmethod\n",
    "    def load_sample(cls, sample_sequence: pl.DataFrame, balance: float=None, **kwargs):\n",
    "        \"\"\"Load price data before running an episode.\"\"\"\n",
    "        env=cls(**kwargs)\n",
    "        cls.data = sample_sequence\n",
    "        cls.T=len(sample_sequence)\n",
    "        cls.balance = balance #none-zero at evaluation\n",
    "        return env\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment to initial state\"\"\"\n",
    "        for key, val in self._defaults.items():\n",
    "            setattr(self, key, val)\n",
    "        self.data = None\n",
    "        self.T=None\n",
    "        self.balance = None\n",
    "    \n",
    "    def step(self) -> pl.DataFrame:           \n",
    "        #combine the states and rewards into one exp_replay\n",
    "        # Get current, next observation\n",
    "        current_state, next_state = self._get_observation()\n",
    "\n",
    "        # Calculate rewards of nex_state based on actions from the current state, normalised if non `eval_mode` \n",
    "        rewards = self._reward_function()\n",
    "        \n",
    "        return current_state, rewards, next_state \n",
    "    \n",
    "    def _get_observation(self) -> pl.DataFrame: \n",
    "        \"\"\"\n",
    "        Get (current + next) observations, later on the (actor + current + next) observations method can be tried in place of argmax_a(q_current). \n",
    "        \"\"\"\n",
    "        stats_mean=self.data.mean()\n",
    "        stats_std=self.data.std()\n",
    "        midpoint = self.T // 2\n",
    "        s_0 = self.data.slice(0, midpoint + (1 if self.T % 2 != 0 else 0))\n",
    "        s_1 = self.data.slice(midpoint)\n",
    "        \n",
    "        normalize_expr = lambda df: [\n",
    "            ((pl.col(col) - pl.col(col).mean()) / (pl.col(col).std() + 1e-6)).alias(col)\n",
    "            for col in df.columns\n",
    "        ] \"\"\"???need to handle the categorical columns but the elements are in int/float\"\"\"\n",
    "        s_0 = s_0.with_columns(normalize_expr(s_0))\n",
    "        s_1 = s_1.with_columns(normalize_expr(s_1))\n",
    "        return s_0, s_1 #pl.df with normalised cols\n",
    "    \n",
    "    def _reward_function(self) -> pl.DataFrame: \n",
    "        actions = [-1, 0, 1]\n",
    "        prices=self.data[\"adj_close\"].to_numpy() #result a 1D tensor\n",
    "        if self.balance is not None:\n",
    "            trade_principal=self.balance\n",
    "        else:\n",
    "            trade_principal=self.trade_principal\n",
    "\n",
    "        # Handle both even and odd T to select from the \"adj_close\" column of the original dataframe\n",
    "        midpoint = self.T // 2\n",
    "        pos_open_price = self.data[midpoint] \n",
    "        pos_close_price = self.data[-1] \n",
    "        \"\"\"#?need a control to cap the total cost by the ceiling of $principal\"\"\"\n",
    "        trade_lots = trade_principal // pos_open_price \n",
    "        trade_open_cost = trade_lots * pos_open_price * (1 + self.fee_rate)\n",
    "        trade_close_nav = trade_lots * pos_close_price * (1 - self.fee_rate)\n",
    "\n",
    "        pnl = torch.log(trade_close_nav) - torch.log(trade_open_cost) \n",
    "        act = torch.tensor(actions)\n",
    "        \"\"\"#???consider to add a scaler to penalize the negative `pnl`\"\"\"\n",
    "        rewards = pnl * act \n",
    "        rewards_norm = (rewards - data.mean()) / (data.std() + 1e-6) #use currnt_states stats\n",
    "\n",
    "        if self.eval_mode:\n",
    "            return rewards\n",
    "            \n",
    "        return rewards_norm #1D tensors, the three elements represent rewards corresponding to three actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "exp_replay = namedtuple(\"exp_replay\",[\n",
    "    \"current_state\",\n",
    "    \"act_rewards\",\n",
    "    \"next_state\"\n",
    "]) #the input format for the `ReplayMemory`\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        \"\"\"\n",
    "        Memory holder for namedtuples with fixed capacity.\n",
    "        \n",
    "        Args:\n",
    "            capacity (int): Maximum number of namedtuples to store\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.memory = []  # List to store namedtuples\n",
    "        self.position = 0  # Current position for circular buffer\n",
    "    \n",
    "    def store(self, exp: exp_replay) -> list: \n",
    "        if len(self.memory) < self.capacity:\n",
    "            # Memory not full, append to end\n",
    "            self.memory.append(exp)\n",
    "        else:\n",
    "            # Memory full, overwrite oldest item (circular buffer)\n",
    "            self.memory[self.position] = exp\n",
    "            self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Clear all memory for new episode\"\"\"\n",
    "        self.memory.clear()\n",
    "        self.position = 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current number of items in memory\"\"\"\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Access items by index\"\"\"\n",
    "        return self.memory[index]\n",
    "    \n",
    "    def get_all(self):\n",
    "        \"\"\"Get all stored namedtuples\"\"\"\n",
    "        return self.memory.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c51output = namedtuple(\"c51output\",[\n",
    "    \"q_prob\",  # Probabilities for each atom of each action\n",
    "    \"q_val\"      # Expected Q-values for each action\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class auto_input_norm_GRN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int, \n",
    "                 output_size: int=None, \n",
    "                 context_size: int=None, \n",
    "                 dropout: float=None\n",
    "                ):\n",
    "        super(auto_input_norm_GRN, self).__init__()\n",
    "        \"\"\"\n",
    "        inputs are all been norm for all linear net\n",
    "        context: is meta info to be encoded through a separate `GRN(VSN)`, \n",
    "                so it is already a norm output from the processing net, as well as the dropout is done inside the `GRN`\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.LayerNorm(input_size),\n",
    "            nn.Linear(input_size, hidden_size, bias=False)\n",
    "        )\n",
    "        #self.act = nn.ELU(), F.elu() instead\n",
    "\n",
    "        if context_size is not None:\n",
    "            self.fc_context=nn.Linear(context_size, hidden_size, bias=False)\n",
    "\n",
    "        if output_size is not None and output_size != input_size:\n",
    "            _output_size=output_size\n",
    "            self.skip=nn.Sequential(\n",
    "                nn.LayerNorm(input_size),\n",
    "                nn.Linear(input_size, _output_size, bias=False)\n",
    "            )\n",
    "        else:\n",
    "            _output_size=input_size\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size, _output_size, bias=False)\n",
    "        self.norm=nn.LayNorm(_output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, context: torch.Tensor=None):\n",
    "        \"\"\"\n",
    "        x needs to be Dropout preprocessd from embedding, the norm of input will be taken care by the network\n",
    "        \"\"\"\n",
    "        skip=x\n",
    "        if hasattr(self, \"skip\"):\n",
    "            skip=self.skip(skip) \n",
    "            \n",
    "        x=self.fc1(x)\n",
    "        if context is not None and hasattr(self, \"fc_context\"):\n",
    "            context=self.fc_context(context)\n",
    "            x=x+context\n",
    "\n",
    "        x=F.elu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.dropout(x)\n",
    "\n",
    "        x=F.glu(torch.cat([x, x], dim=-1))\n",
    "        return self.norm(skip+x)\n",
    "        \n",
    "class VariableSelectionNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputs: list[str], #both continuous and categorials pre-embedded before go through VSN\n",
    "        model_input_size: int, #embedding size\n",
    "        hidden_size: int,\n",
    "        output_size: int = None,\n",
    "        context_size: int = None,\n",
    "        dropout: float = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        for multi inputs only\n",
    "        according to paper, all embeddings are sharing the same size for both real, and categorical inputs\n",
    "        \"\"\"\n",
    "        super(VariableSelectionNet, self).__init__()\n",
    "        self.inputs=inputs\n",
    "        self.model_input_size=model_input_size\n",
    "        #self.output_size=output_size if output_size is not None else model_input_size\n",
    "\n",
    "        #flatten inputs + context GRN\n",
    "        self.num_input=len(inputs)\n",
    "        self.inputs_total_size=self.num_inputs*self.model_input_size\n",
    "        self.flattened_grn = auto_input_norm_GRN(\n",
    "            self.inputs_total_size,\n",
    "            hidden_size,\n",
    "            self.num_inputs,\n",
    "            context_size,\n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        #individual grns, assume all the inputs are embedded into the same size\n",
    "        self.single_variable_grns = nn.ModuleDict()\n",
    "        self.single_variable_grns[name]=auto_input_norm_GRN(\n",
    "            self.model_input_size,\n",
    "            hidden_size,\n",
    "            output_size,\n",
    "            context_size,\n",
    "            dropout\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: dict[str, torch.Tensor], context: torch.Tensor=None):\n",
    "        \"\"\"\n",
    "        input tensors in x need to be Dropout preprocessd\n",
    "        \"\"\"\n",
    "        # transform single variables\n",
    "        T = x[next(iter(x))].shape[0] #assume all the inputs are 2D by (T, H)\n",
    "        H = self.model_input_size\n",
    "        N = self.num_inputs\n",
    "        device = device if device is not None else x[next(iter(x))].device\n",
    "        dtype = x[next(iter(x))].dtype #it is crucial to keep the price at the 1st position\n",
    "\n",
    "        flatten_inputs = torch.emtpy(T, self.inputs_total_size, dtype=dtype, device=device)\n",
    "        inputs_GRNs = torch.emtpy(T, H, N, dtype=dtype, device=device)\n",
    "        for i, name in enumerate(self.inputs):\n",
    "            flatten_inputs[..., i * H:(i + 1) * H] = x[name]\n",
    "            single_input_grn = self.single_variable_grns[name](x[name])\n",
    "            inputs_GRNs[..., i] = single_input_grn.to(dtype=dtype)\n",
    "        \n",
    "        vs_weights = self.flattened_grn(flatten_inputs, context)\n",
    "        vs_weights = F.softmax(vs_weights, dim=-1).unsqueeze(-2) #add broadcasting dim of (T, 1, N) to match (T, H, N)\n",
    "        output = flatten_inputs*vs_weights \n",
    "        output = output.sum(dim=-1) #reduce the last dim of the N\n",
    "        return output\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"with output in the form of dropout_add_norm\"\"\"\n",
    "    def __init__(self, input_size: int, dropout: float=None):\n",
    "        super(MLP, self).__init__()\n",
    "        self.expand=nn.Lienar(input_size, input_size*4, bias=False)\n",
    "        self.compress=nn.Linear(input_size*4, input_size, bias=False)\n",
    "        self.norm=nn.LayerNorm(input_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.0)\n",
    "\n",
    "    def forward(x: torch.Tensor):\n",
    "        skip=x\n",
    "        x=self.expand(x)\n",
    "        x=F.elu(x)\n",
    "        x=self.compress(x)\n",
    "        x=self.dropout(x)\n",
    "\n",
    "        out=x+skip\n",
    "        return self.norm(out)\n",
    "        \n",
    "class VSNencoder_LSTM_QN(nn.Module):\n",
    "    def __init__(self,\n",
    "                # Required fields (no defaults)\n",
    "                continuous_inputs: list[str],\n",
    "                temporal_dim: int,\n",
    "                lstm_hidden_dim: int,\n",
    "                action_size: int,\n",
    "            \n",
    "                # Optional fields (with defaults)\n",
    "                continuous_embedding_sizes: Optional[dict[str, int]] = None,\n",
    "                categorical_embedding_sizes: Optional[dict[str, tuple[int, int]]] = None,\n",
    "                default_model_dim: int = 64,\n",
    "                context_size: Optional[int] = None,\n",
    "                grn_hidden_dim: Optional[int] = None,\n",
    "                grn_output_dim: Optional[int] = None,\n",
    "                batch_first: bool = True,\n",
    "                num_layers: Optional[int] = None,\n",
    "                bidirectional: Optional[bool] = None,\n",
    "                dropout: Optional[float] = None,\n",
    "                num_atoms: int =51,\n",
    "                atom_start: float = -10,\n",
    "                atom_end: float = 10\n",
    "                ):\n",
    "        \"\"\"\n",
    "        continuous_input_sizes: all temporal data are in shape of (T, H), H=1, where T is temporal_dim\n",
    "        assumption: *`continuous_inputs` and `categorical_inputs` are all sharing the same `embedding_size`, default in `model_size`. \n",
    "                    *`context` is by putting `static_inputs` through a separate `static_inputs_VSN`-> `context_GRN`, \n",
    "                        `context_dim`==`embeding_size` of of the `continuous_inputs` and `categorical_inputs`.\n",
    "        LSTM is batch 1st\n",
    "        \"\"\"\n",
    "        super(VSNencoder_LSTM_QN, self).__init__()\n",
    "        self.x_continuous=continuous_inputs    \n",
    "        #continuous embeddings\n",
    "        self.cont_embeddings = nn.ModuleDict(\n",
    "            {\n",
    "                name: nn.Linear(\n",
    "                    1,\n",
    "                    self.continuous_embedding_sizes.get(\n",
    "                        name, default_model_dim\n",
    "                    )\n",
    "                )\n",
    "                for name in continuous_inputs\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        #categorical embeddings\n",
    "        if categorical_embedding_sizes:\n",
    "            # Get embedding dimensions\n",
    "            _cat_dims = [size[1] if isinstance(size, tuple) else size for size in categorical_embedding_sizes.values()]\n",
    "            # Get first dimension for comparison\n",
    "            _checker_cat_dim = _cat_dims[0]\n",
    "            # Check for uniform dimensions or mismatch with continuous/default\n",
    "            if (len(set(_cat_dims)) > 1 or\n",
    "                _checker_cat_dim != (\n",
    "                    next(iter(continuous_embedding_sizes.values()))[1] if isinstance(\n",
    "                        next(iter(continuous_embedding_sizes.values())), tuple\n",
    "                    ) else next(iter(continuous_embedding_sizes.values()))\n",
    "                    if continuous_embedding_sizes else default_model_dim\n",
    "                )):\n",
    "                raise ValueError(\n",
    "                    f\"All categorical embedding dimensions must be equal and match \"\n",
    "                    f\"continuous embedding size or default_model_dim ({default_model_dim}). \"\n",
    "                    f\"Input categorical dimensions: {_cat_dims} for categories {list(categorical_embedding_sizes.keys())}\"\n",
    "                )\n",
    "            else:\n",
    "                self.x_categoricals=list(categorical_embedding_sizes.keys())\n",
    "                self.cat_embeddings=MultiEmbedding(\n",
    "                    embedding_sizes=categorical_embedding_sizes,\n",
    "                    x_categoricals=self.x_categoricals\n",
    "                )\n",
    "        \n",
    "        #Initialize VSN for multi inputs, otherwise single GRN\n",
    "        _model_input_size=(\n",
    "                continuous_embedding_sizes[next(iter(continuous_embedding_sizes))] \n",
    "                if continuous_embedding_sizes \n",
    "                else default_model_dim\n",
    "            )\n",
    "        _grn_hidden=grn_hidden_dim if grn_hidden_dim is not None else default_model_dim\n",
    "        if len(continuous_inputs)>1 or categorical_inputs_sizes is not None:\n",
    "            _all_inputs_list=continuous_inputs+list(categorical_inputs_sizes.keys() if categorical_inputs_sizes is not None else [])\n",
    "            self.vsn=VariableSelectionNet(\n",
    "                inputs=_all_inputs_list,\n",
    "                model_input_size=_model_input_size,\n",
    "                hidden_size=_grn_hidden,\n",
    "                output_size=grn_output_dim,\n",
    "                context_size=context_size,\n",
    "                dropout=dropout\n",
    "            )\n",
    "        else: #at only single input case:\n",
    "            self.grn=auto_input_norm_GRN(\n",
    "                input_size=_model_input_size, \n",
    "                hidden_size=_grn_hidden,\n",
    "                output_size=grn_output_dim, \n",
    "                context_size=context_size, \n",
    "                dropout=dropout\n",
    "            )\n",
    "        \n",
    "        # Initialize LSTM with conditional parameters\n",
    "        _lstm_input_size=grn_output_dim if grn_output_dim is not None else _model_input_size\n",
    "        _lstm_hidden_dim=lstm_hidden_dim if lstm_hidden_dim is not None else default_model_dim\n",
    "        \n",
    "        kwargs={}\n",
    "        if num_layers:\n",
    "            kwargs['num_layers']=num_layers\n",
    "\n",
    "        self.bi_lstm=bidirectional\n",
    "        if bidirectional:\n",
    "            kwargs['bidirectional']=bidirectional\n",
    "            #at bidirectional case, transform the hidden_out to match input/skip\n",
    "            self.forward_backward_fc=nn.Sequential(\n",
    "                nn.ELU(),\n",
    "                nn.Linear(_lstm_hidden_dim*2, _lstm_input_size, bias=False)\n",
    "            )\n",
    "        else _lstm_hidden_dim!=_lstm_input_size:\n",
    "            #at unit directional case, linear transform the hidden_out to match the input_size\n",
    "            self.forward_fc=nn.Sequential(\n",
    "                nn.ELU(),\n",
    "                nn.Linear(_lstm_hidden_dim, _lstm_input_size, bias=False)\n",
    "            ) \n",
    "\n",
    "        self.lstm=nn.LSTM(\n",
    "            input_size=_lstm_input_size,\n",
    "            hidden_size=_lstm_hidden_dim,\n",
    "            batch_first=batch_first, \n",
    "            bias=False,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.0)\n",
    "        self.norm=nn.LayerNorm(_lstm_input_size)\n",
    "            \n",
    "        #MLP->action mapping\n",
    "        \"\"\"need to map the (T, H) into (action, atoms)\"\"\"\n",
    "        self.num_atoms=num_atoms\n",
    "        self.atoms=torch.linspace(atom_start, atom_end, num_atoms) #1D tensor\n",
    "\n",
    "        self.mlp=MLP(_lstm_input_size, dropout)\n",
    "        self.proj_flat=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(temporal_dim*_lstm_input_size, action_size*num_atoms, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "                \n",
    "        elif isinstance(module, nn.LSTM):\n",
    "            for name, param in module.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.kaiming_normal_(param, mode='fan_in', nonlinearity='relu')\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(param)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "    \n",
    "    def forward(self, x: dict[str, torch.Tensor], context: torch.Tensor=None):\n",
    "        #continuous embedding \n",
    "        x_embed={name: self.cont_embeddings(x[name]) for name in self.x_continuous if name in x}\n",
    "        #categorical embedding\n",
    "        if hasattr(self, \"x_categoricals\"):\n",
    "            x_cat={name: self.cat_embeddings(x[name]) for name in self.x_categoricals if name in x}\n",
    "            x_embed=x_embed.update(x_cat)\n",
    "\n",
    "        x_embed={key: self.dropout(value) for key, value in x_embed.items()}\n",
    "\n",
    "        #encoder layer\n",
    "        if hasattr(self, \"vsn\"):\n",
    "            if context is not None and context.shape==x_embed[next(iter(x_embed))].shape:\n",
    "                input_encoder=self.norm(self.vsn(x_embed, context)) #`x` norm has been taken care of by the `vsn`\n",
    "            elif context is not None and context.shape!=x_embed[next(iter(x_embed))].shape:\n",
    "                return f\"{context} shape does not match embedding size of the model\" #???consider to optimise this scenario in future\n",
    "            else:\n",
    "                input_encoder=self.norm(self.vsn(x_embed))\n",
    "\n",
    "        if hasattr(self, \"grn\"):\n",
    "            if context is not None and context.shape==x_embed[next(iter(x_embed))].shape:\n",
    "                input_encoder=self.grn(x_embed, context)\n",
    "            elif context is not None and context.shape!=x_embed[next(iter(x_embed))].shape:\n",
    "                return f\"{context} shape does not match embedding size of the model\"\n",
    "            else:\n",
    "                input_encoder=self.grn(x_embed) #norm already in GRN final out, and dropout is also in place of GRN's Dropout&GatedAddNorm\n",
    "        \n",
    "        #LSTM layer\n",
    "        lstm_out, _=self.lstm(input_encoder)\n",
    "        if self.bi_lstm:\n",
    "            lstm_out=self.forward_backwarod_fc(lstm_out)\n",
    "        else hasattr(self, \"forward_fc\"):\n",
    "            lstm_out=self.forward_fc(lstm_out)\n",
    "        lstm_out=self.dropout(lstm_out)\n",
    "        lstm_out=self.norm(input_encoder+F.glu(torch.cat([lstm_out, lstm_out], dim=-1)))\n",
    "\n",
    "        #MLP layer\n",
    "        out=self.mlp(lstm_out)\n",
    "        \n",
    "        #action_atoms mapping layer\n",
    "        out=self.proj_flat(out)\n",
    "        q_logits=q_logits.view(-1, action_size, self.num_atoms) #in shape of (batch, action, num_atoms)\n",
    "        q_prob=F.softmax(q_logits, dim=-1)\n",
    "        q_val=(q_prob*self.atoms.unsqueeze(0).unsqueeze(0)).sum(dim=-1).detach() #in shape of (batch, action), expectation of the distribution\n",
    "        return c51output(q_prob=q_prob, q_val=q_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#wrapper to enable dot-access for `nn.ModuleDict()` sub modules\n",
    "class AttrModuleDict(nn.ModuleDict):\n",
    "    def __getattr__(self, key):\n",
    "        if key in self._modules:\n",
    "            return self._modules[key]\n",
    "        return super().__getattr__(key)\n",
    "\n",
    "class _lambda_(nn.Module): #to be used in `nn.Sequential` for reshaping ops\n",
    "    def __init__(self, func):\n",
    "        super(_lambda_, self).__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "def to_bth_format(tensor, name: str = \"input_tensor\"): # Shape checking and reshaping function for B,T,H format\n",
    "    original_shape = tensor.shape\n",
    "    \n",
    "    if len(original_shape) == 1:  # H -> H,1,1\n",
    "        tensor = tensor.unsqueeze(-1).unsqueeze(-1)\n",
    "    elif len(original_shape) == 2:  # B,H -> B,H,1\n",
    "        tensor = tensor.unsqueeze(2)\n",
    "    elif len(original_shape) >= 4:  # Handle higher dimensions\n",
    "        # Reshape to B,T,H by keeping last dimension as H\n",
    "        tensor = tensor.view(-1, original_shape[-2], original_shape[-1])\n",
    "    \n",
    "    # Final validation\n",
    "    if len(tensor.shape) != 3:\n",
    "        raise ValueError(f\"{name}: Cannot reshape {original_shape} to B,T,H format\")\n",
    "    \n",
    "    #print(f\"{name}: {original_shape} -> {tensor.shape}\")\n",
    "    return tensor\n",
    "\n",
    "class RDQN(nn.Module):\n",
    "    #price only temporal data is a (B, 1, T: treate T as feature_dim), \n",
    "    #real `sample_len`=T is only used when `feature_size` >=2\n",
    "\tdef __init__(self, sample_len=None, feature_size, model_size, action_size, lstm_layers = None, lstm_bidirectional = None):\n",
    "\t\tsuper(DRQN, self).__init__()\n",
    "\t\tself.mlp = nn.ModuleDict(dict(\n",
    "\t\t\tproj = nn.Linear(feature_size, model_size, bias = False),\n",
    "\t\t\tfc = nn.Linear(model_size, model_size, bias = False),\n",
    "            lnorm = nn.LayNorm(model_size),\n",
    "\t\t\tact = nn.ELU()\n",
    "        )) #output shape = B, T, H\n",
    "\n",
    "        m = self.mlp\n",
    "        #mlp forward, in a add&norm structure before the activation\n",
    "        self.mlpf = lambda x: m.act(m.lnorm(m.fc(m.proj(x)) + m.proj(x)))\n",
    "\n",
    "        # Initialize LSTM with conditional parameters\n",
    "        kwargs = {}\n",
    "        if lstm_layers is not None:\n",
    "            kwargs['num_layers'] = lstm_layers\n",
    "        if lstm_bidirectional is not None:\n",
    "            kwargs['bidirectional'] = lstm_bidirectional\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            model_size,\n",
    "            model_size,\n",
    "            batch_first=True, \n",
    "            bias=False,\n",
    "            **kwargs\n",
    "        )\n",
    "    \t\n",
    "        #if the input shape = B, T>1, E, \n",
    "        #then the final output of LSTM in shape B, T>1, H needs to be flattend into B, T for 1D actions across the T\n",
    "        final_in=model_size*(2 if lstm_bidirectional else 1)\n",
    "        if sample_len is not None:\n",
    "            self.output_net = nn.Sequential(\n",
    "                nn.Linear(final_in, 1, bias=False),  # Transforms (batch, T, E) -> (batch, T, 1)\n",
    "                _lambda_(lambda x: x.squeeze(-1)),       # Squeezes to (batch, T)\n",
    "                nn.Linear(sample_size, action_size, bias=False)  # Transforms (batch, T) -> (batch, action_size)\n",
    "            )\n",
    "        else:\n",
    "            self.output_net = nn.Linear(final_in, action_size, bias=False)\n",
    "\n",
    "        # Initialize all weights\n",
    "        #the `.apply()` in pytorch will traverse through all layers defined inside the `__init__`\n",
    "        self.apply(self._init_weights) \n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Comprehensive weight initialization\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.LSTM):\n",
    "            for name, param in module.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.kaiming_normal_(param, mode='fan_in', nonlinearity='relu')\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(param)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "        elif isinstance(module, nn.Conv1d):  # If add conv layers for multi-assets feature layers\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "\tdef forward(self, x: torch.Tensor): #add if 1D data, then flatten the input?\n",
    "\t\tx = self.mlpf(x) #input shape = B, T, E, output shape = B, T, H\n",
    "        lstm_output, _h_c = self.lstm(x) #output.shape = B, T, H\n",
    "\n",
    "\t\tbatch_size, seq_len, h_dim = lstm_output.shape\n",
    "\t\tseq_output = lstm_output.contiguous().view(batch_size, -1) #reshape the output into 2D = B, T*H\n",
    "\n",
    "\t\treturn self.output_fc(seq_output) #final logit in size of B, A, ???need to `.squeeze()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AgentConfig:\n",
    "    # Policy network args\n",
    "    # Required fields (no defaults)\n",
    "    continuous_inputs: list[str]\n",
    "    temporal_dim: int\n",
    "    lstm_hidden_dim: int\n",
    "    action_size: int\n",
    "\n",
    "    # Optional fields (with defaults)\n",
    "    continuous_embedding_sizes: Optional[dict[str, int]] = None\n",
    "    categorical_embedding_sizes: Optional[dict[str, tuple[int, int]]] = None\n",
    "    default_model_dim: int = 64\n",
    "    context_size: Optional[int] = None\n",
    "    grn_hidden_dim: Optional[int] = None\n",
    "    grn_output_dim: Optional[int] = None\n",
    "    batch_first: bool = True\n",
    "    num_layers: Optional[int] = None\n",
    "    bidirectional: Optional[bool] = None\n",
    "    dropout: Optional[float] = None\n",
    "\n",
    "    # Optimizer args\n",
    "    optimizer_config: Optional[dict] = None\n",
    "\n",
    "    # Helper: extract policy_net args\n",
    "    def policy_net_args(self) -> dict:\n",
    "        \"\"\"Return only the args relevant for building the policy net.\"\"\"\n",
    "        # asdict() converts all dataclass fields -> dict\n",
    "        d = asdict(self)\n",
    "        # Drop optimizer_config from the dict\n",
    "        d.pop(\"optimizer_config\", None)\n",
    "        return d\n",
    "\n",
    "def dict_features(x):\n",
    "    dict_x={name: x[:, idx].unsqueeze(-1) for name, idx in col2idx.items()}\n",
    "    return dict_x\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, config: AgentConfig, \n",
    "                 cash_equivalent_ARR: Optional[float]=0.06,\n",
    "                 gradient_clip: Optional[float]=1.0\n",
    "                ): \n",
    "        self.action_size = config.action_size\n",
    "        self.policy_net = VSNencoder_LSTM_QN(**config.policy_net_args())\n",
    "        self.target_net = VSNencoder_LSTM_QN(**config.policy_net_args())\n",
    "        self.target_net.update_target_net() #to make sure the initial param of `targe_net` is same as `policy_net`\n",
    "        self.target_net.eval() #disable `Dropout`\n",
    "\n",
    "        self.gamma = self._gamma(config.temporal_dim, cash_equivalent_ARR)\n",
    "\n",
    "        self.optimizer_config = config.optimizer_config or {}\n",
    "        self.optimizer = self.configure_optimizer()\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.grad_clip = gradient_clip\n",
    "    \n",
    "    def _gamma(self, observe_len, ARR):\n",
    "        \"\"\"\n",
    "        assumption of a fixed hoding period = input period\n",
    "        modification needed, if the input bar period is < daily OHLCV\n",
    "        \n",
    "        \"\"\"\n",
    "        r=math.log(1 + ARR)*oberve_len/365\n",
    "        return math.exp(-r)\n",
    "    \n",
    "    def update_target_net(self): #to be sued for `target_net` update \n",
    "        self.target_net.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "    def mem_buffer(self, memory: list[exp_replay], device): \n",
    "        \"\"\"grouping the experiences/MDP elements into tensors for training\"\"\"\n",
    "        # Sample mini batch from memory if needed:\n",
    "        #batch = random.sample(external_memory, self.batch_size) \n",
    "        \n",
    "        #experiences = exp_replay(*zip(*batch)) #for mini batch from above\n",
    "        #for non minibatch:\n",
    "        _experiences = exp_replay(*zip(*memory))\n",
    "        \n",
    "        # Convert to tensors for network processing\n",
    "        #the state elements are in tensors shape = (T, E)\n",
    "        current_states = torch.stack(_experiences.current_state, dim=0).to(device)\n",
    "        #actions = torch.stack(experiences.actions, dim=0).to(device) if needed, but modification needs to be done in `exp_replay`\n",
    "        rewards = torch.stack(_experiences.act_rewards, dim=0).to(device)\n",
    "        next_states = torch.stack(_experiences.next_state, dim=0).to(device)\n",
    "        #dones = torch.stack(experiences.done, dim=0).to(device) if needed\n",
    "        return current_states, rewards, next_states\n",
    "    \n",
    "    def act_reward(self, current_states, rewards, batch_size=None, eval_mode=True):\n",
    "        \"\"\"Select action based on current observation\"\"\"\n",
    "        current_states=dict_features(current_states) #batch size of current_states\n",
    "        self.policy_net.eval()\n",
    "        with torch.no_grad():\n",
    "            qs = self.policy_net(current_states) #output in shape of (B, A)\n",
    "        \n",
    "        if eval_mode:\n",
    "            a_max = qs.argmax(dim=1)\n",
    "            reward_max = rewards.gather(1, max_a.unsequeeze(1)).squeeze().cpu().numpy() #1D numpy array for plotting\n",
    "            return reward_max\n",
    "        else: \"\"\"???need to elaborate how this random actions be used\"\"\"\n",
    "            if batch_size is None:\n",
    "                logging.warning(\"batch_size is missing in process_states\")\n",
    "                raise ValueError(\"batch_size is required and cannot be None\")\n",
    "            else: \n",
    "                a_rand = torch.randint(0, self.action_size, (batch_size, 1), device=rewards.device)\n",
    "                reward_rand = rewards.gather(1, a_rand).squeeze().cpu().numpy() #back to 1D array\n",
    "                return a_rand, reward_rand\n",
    "\n",
    "    def configure_optimiser(self):#, weight_decay: float, learning_rate: float, betas: tuple[float, float]):\n",
    "        # start with all of the candidate parameters\n",
    "        param_dict = {pn: p for pn, p in self.policy_net.named_parameters()}\n",
    "        # filter out those that do not require grad\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        _device_type = next(self.policy_net.parameters()).device.type\n",
    "        fused_available = 'fused' in inspect.signature(optim.AdamW).parameters\n",
    "        use_fused = fused_available and _device_type == 'cuda'\n",
    "        extra_args = dict(fused=True) if use_fused else {}\n",
    "        all_args = {**self.optimizer_config, **extra_args}\n",
    "        optimizer = optim.AdamW(optim_groups, **all_args)\n",
    "        print(f\"using fused AdamW: {use_fused} on device {_device_type}\")\n",
    "        return optimizer\n",
    "        \n",
    "    def optimise(self, current_states, rewards, next_states): #the states shape=B T E, and rewards shape=B, A\n",
    "        #use policy_net to find `current_state` q's, and the argmax_a of `next_state` \n",
    "        current_qs = self.policy_net(current_states) #output size = B, A\n",
    "        next_max_a = self.policy_net(next_states).argmax(dim=1) #argmax for each sample (B, T, E) -> 1D LongTensor dim = (B,)\n",
    "        gamma = self.gamma\n",
    "        self.target_net.eval()\n",
    "        with torch.no_grad():\n",
    "            target_q_on_max_a = self.target_net(next_states).gether(1, next_max_a.unsqueeze(1))\n",
    "            y = rewards + (gamma * target_q_on_max_a) #size = B, A, and on \"device\" \n",
    "        loss = self.loss_fn(current_qs, y) #no `detach` is needed since no intermediate ops with `y`\n",
    "                \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Add gradient clipping here\n",
    "        if self.grad_clip > 0: # assuming `self.grad_clip` defined\n",
    "            nn.utils.clip_grad_norm_(self.policy.parameters(), self.grad_clip)\n",
    "        self.optimizer.step()\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#training devic env preparation:\n",
    "def get_device(preferred_device=None):\n",
    "    \"\"\"\n",
    "    Get the best available device\n",
    "    \"\"\"\n",
    "    if preferred_device:\n",
    "        if preferred_device == \"cuda\" and torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        elif preferred_device == \"mps\" and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "    \n",
    "    # Auto-selection\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def setup_device_env(use_cuda=True, seed=None):\n",
    "    \"\"\"\n",
    "    Setup device environment\n",
    "    \"\"\"\n",
    "    # Pick the device first\n",
    "    device = get_device(\"cuda\") if use_cuda else get_device()\n",
    "\n",
    "    #Seed everything\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "        elif device.type == \"mps\":\n",
    "            torch.mps.manual_seed(seed)\n",
    "\n",
    "    #Print system info\n",
    "    print(f\"Using device: {device}\")\n",
    "    if device.type == \"cuda\":\n",
    "        print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    elif device.type == \"mps\":\n",
    "        print(\"Using Metal Performance Shaders\")\n",
    "    return device\n",
    "\n",
    "def initialize_agent_with_device(agent, device):\n",
    "    \"\"\"\n",
    "    Move agent models to the specified device\n",
    "    This keeps device logic separate from the Agent class\n",
    "    \"\"\"\n",
    "    # Move models to device\n",
    "    agent.policy_network = agent.policy_net.to(device)\n",
    "    agent.target_network = agent.target_net.to(device)\n",
    "        \n",
    "    print(f\"Agent models moved to {device}\")\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#RAM and VRAM management\n",
    "def log_memory_usage(device):\n",
    "     allocated_mb = reserved_mb = total_mb = 0.0\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        allocated_mb = torch.cuda.memory_allocated(device) / 1024**2\n",
    "        reserved_mb  = torch.cuda.memory_reserved(device) / 1024**2\n",
    "        total_mb     = torch.cuda.get_device_properties(device).total_memory / 1024**2\n",
    "    elif device.type == \"mps\":\n",
    "        allocated_mb = torch.mps.current_allocated_memory() / 1024**2\n",
    "        reserved_mb  = allocated_mb  # no reserved metric yet\n",
    "        total_mb     = torch.mps.current_allocated_memory() / 1024**2  # Approximation  MPS API is limited\n",
    "    else:  # CPU\n",
    "        allocated_mb = reserved_mb = 0.0\n",
    "        total_mb     = psutil.virtual_memory().total / 1024**2\n",
    "\n",
    "    return allocated_mb, reserved_mb, total_mb\n",
    "\n",
    "def clear_device_cache(device):\n",
    "    \"\"\"\n",
    "    Clears device cache for CUDA, or runs GC for MPS/CPU.\n",
    "    \"\"\"\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    elif device.type == \"mps\":\n",
    "        # No empty_cache for MPS  force garbage collection\n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache() if hasattr(torch.mps, \"empty_cache\") else None\n",
    "    else:  # CPU\n",
    "        gc.collect()\n",
    "\n",
    "def manage_vram(device, threshold_percent, episode):\n",
    "    \"\"\"\n",
    "    Logs and clears memory if usage exceeds threshold_percent (0-100).\n",
    "    \"\"\"\n",
    "    allocated_mb, reserved_mb, total_mb = log_memory_usage(device)\n",
    "    usage_percent = (allocated_mb / total_mb) * 100 if total_mb > 0 else 0\n",
    "\n",
    "    if usage_percent > threshold_percent:\n",
    "        clear_device_cache(device)\n",
    "        allocated_mb, reserved_mb, total_mb = log_memory_usage(device)\n",
    "        usage_percent = (allocated_mb / total_mb) * 100\n",
    "        print(f\"[VRAM Management] Cleared cache at episode {episode}, \"\n",
    "              f\"Allocated: {allocated_mb:.2f} MB ({usage_percent:.1f}%), \"\n",
    "              f\"Total: {total_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def agent_trainer_with_vram_management(\n",
    "    agent, df, \n",
    "    sample_len: int, episodes: int,\n",
    "    batch_size: int, num_batches: int=None,\n",
    "    memory_capacity: int,\n",
    "    cuda: bool, seed: int, \n",
    "    memory_threshold_pct: int,\n",
    "    target_update_freq: int=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete training loop with strategic cache management.\n",
    "    Returns:\n",
    "        trained_agent, training_stats (dict for plotting)\n",
    "    \"\"\"\n",
    "    training_stats_log = {\n",
    "        \"episode_pre_rewards_quantiles\": [],\n",
    "        \"episode_loss\": []\n",
    "    }\n",
    "\n",
    "    device = setup_device_env(use_cuda=cuda, seed=seed)\n",
    "    agent = initialize_agent_with_device(agent, device)\n",
    "    \n",
    "    #Get N batches from the sampler for this episode\n",
    "    dataset = DataSampler(df, sample_length)\n",
    "    batch_generator = dataset.batch_generator(batch_size, num_batches) \n",
    "\n",
    "    \"\"\"\n",
    "    #can setup kwargs for Env2D\n",
    "    \"\"\"\n",
    "    Env=Env2D()\n",
    "    ReplayMem = ReplayMemory(memory_capacity)\n",
    "    for episode in range(episodes):\n",
    "        # reset per-episode stats\n",
    "        Env.reset()\n",
    "        ReplayMem.reset()\n",
    "        exp_memory=ReplayMem.memory\n",
    "        #`num_batches=None` is infinite case that generate batch on-dmand\n",
    "        batch = next(batch_generator)\n",
    "\n",
    "        for samples in batch: #setting up the trajectory \n",
    "            env = Env.load_sample(samples)\n",
    "            current_state, rewards, next_states = env.step()\n",
    "            exp = exp_replay(current_state, rewards, next_states)\n",
    "            ReplayMem.store(exp)\n",
    "        \n",
    "        #Train/optimise using the grouped memory buffer\n",
    "        if len(exp_memory) < batch_size:\n",
    "            logging.warning(f\"Skipping optimise: memory size {len(exp_memory)} < batch_size {batch_size}\")\n",
    "            raise ValueError(f\"Memory size {len(exp_memory)} should = batch_size {batch_size}\")\n",
    "        else:\n",
    "            current_s, r, next_s=agent.mem_buffer(exp_memory, device)\n",
    "            if not (current_s.shape[0] == r.shape[0] == next_s.shape[0]):\n",
    "                logging.warning(f\"Skipping optimise: tensor first dimensions do not match or not equal to batch_size \"\n",
    "                                f\"(state={batch.state.shape[0]}, action={batch.action.shape[0]}, reward={batch.reward.shape[0]}, expected={bs})\")\n",
    "                raise ValueError(f\"s_0, r_1, s_1 tensors batch sizes do not match\")\n",
    "            else:\n",
    "                batch_rewards = agent.act_reward(current_s, r)\n",
    "                batch_rewards_quantiles = np.quantile(batch_rewards, [0.02, 0.05, 0.25, 0.5, 0.75, 0.95, 0.98])\n",
    "                batch_loss = agent.optimise(current_s, r, next_s)\n",
    "                break batch_rewards_quantiles, batch_loss\n",
    "        \n",
    "        # Store stats\n",
    "        training_stats['episode_pre_rewards_quantiles'].append(batch_rewards_quantiles)\n",
    "        training_stats['episode_loss'].append(batch_loss)\n",
    "        \n",
    "        # Proactive cache clearing if threshold % exceeded\n",
    "        manage_vram(device, threshold_percent, episode)\n",
    "        \n",
    "        # Target network update\n",
    "        if episode > 0 and episode % target_update_freq == 0:\n",
    "            agent.update_target_network()\n",
    "            print(f\"Episode {episode}: Target network updated\")\n",
    "    \n",
    "    return agent, training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "agent = DQNAgent(state_size=4, action_size=2)\n",
    "\n",
    "trained_agent, stats = train_dqn_with_cache_management(\n",
    "    agent, df, \n",
    "    episodes=1000, \n",
    "    cuda=True, seed=666,\n",
    "    target_update_freq=100, \n",
    "    memory_threshold_pct=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def agent_trainer(agent, environment, episodes=1000, use_cuda=True, \n",
    "                     target_update_freq=100, save_freq=500, seed=666, \n",
    "                     model_save_path=None):\n",
    "    \"\"\"\n",
    "    Complete training loop that handles all device-related operations\n",
    "    \"\"\"\n",
    "    # Setup device environment\n",
    "    device = setup_device_env(use_cuda = use_cuda, seed = seed)\n",
    "    \n",
    "    # Move agent models to device\n",
    "    agent = initialize_agent_with_device(agent, device)\n",
    "    \n",
    "    print(f\"Starting training for {episodes} episodes.../n\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = environment.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # Agent action (device passed to act method)\n",
    "            action = agent.act(state, device)\n",
    "            \n",
    "            # Environment step\n",
    "            next_state, reward, done, _ = environment.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Store experience\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            \n",
    "            state = next_state\n",
    "        \n",
    "        scores.append(total_reward)\n",
    "        \n",
    "        # Train the agent (device passed to optimizer method)\n",
    "        agent.optimizer(device)\n",
    "        \n",
    "        # Update target network\n",
    "        if episode % target_update_freq == 0:\n",
    "            agent.update_target_network()\n",
    "            print(f\"Episode {episode}: Target network updated\")\n",
    "        \n",
    "        # Save model\n",
    "        if model_save_path and episode % save_freq == 0:\n",
    "            agent.save(f\"{model_save_path}_episode_{episode}.pth\")\n",
    "            print(f\"Episode {episode}: Model saved\")\n",
    "        \n",
    "        # Logging\n",
    "        if episode % 100 == 0:\n",
    "            avg_score = np.mean(scores) if scores else 0\n",
    "            print(f\"Episode {episode}, Average Score: {avg_score:.2f}, \"\n",
    "                  f\"Epsilon: {agent.epsilon:.3f}\")\n",
    "            \n",
    "            # Track best performance\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                if model_save_path:\n",
    "                    agent.save(f\"{model_save_path}_best.pth\")\n",
    "    \n",
    "    print(f\"Training completed! Best average score: {best_score:.2f}\")\n",
    "    return agent\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create agent (no device specified)\n",
    "    agent = DQNAgent(\n",
    "        state_size=4,\n",
    "        action_size=2,\n",
    "        lr=0.001,\n",
    "        batch_size=64\n",
    "    )\n",
    "    \n",
    "    # For real environment, you would use:\n",
    "    # import gym\n",
    "    # env = gym.make('CartPole-v1')\n",
    "    \n",
    "    # Mock environment for demonstration\n",
    "    class MockEnvironment:\n",
    "        def __init__(self):\n",
    "            self.step_count = 0\n",
    "            \n",
    "        def reset(self):\n",
    "            self.step_count = 0\n",
    "            return np.random.randn(4)\n",
    "            \n",
    "        def step(self, action):\n",
    "            self.step_count += 1\n",
    "            state = np.random.randn(4)\n",
    "            reward = 1.0\n",
    "            done = self.step_count >= 200\n",
    "            return state, reward, done, {}\n",
    "    \n",
    "    env = MockEnvironment()\n",
    "    \n",
    "    # Train with automatic device setup\n",
    "    trained_agent = train_dqn_agent(\n",
    "        agent=agent,\n",
    "        environment=env,\n",
    "        episodes=1000,\n",
    "        use_cuda=True,  # Will auto-detect and use CUDA if available\n",
    "        target_update_freq=100,\n",
    "        model_save_path=\"dqn_model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create dataset with random sampling\n",
    "sample_length = 10  # 2 x states length = T\n",
    "max_overlap = 0.8     # Allow up to 80% overlap between sequences\n",
    "\n",
    "dataset = DataSampler(\n",
    "    dataframe = df, \n",
    "    sample_length = sample_length, \n",
    "    max_overlap_ratio = max_overlap\n",
    ")\n",
    "\n",
    "# Custom collate function with verbose output for non tensor Dataset:\n",
    "def verbose_collate_fn(batch):\n",
    "    #print(f\"\\nCollate function received batch of {len(batch)} DataFrames:\")\n",
    "    #for i, df in enumerate(batch):\n",
    "    #    print(f\"  DataFrame {i}: shape {df.shape}, start values: {list(df.iloc[0])}\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    numpy_arrays = [df.values for df in batch]\n",
    "    stacked = np.stack(numpy_arrays)\n",
    "    tensor_batch = torch.FloatTensor(stacked)\n",
    "    \n",
    "    print(f\"  Final batch tensor shape: {tensor_batch.shape}\")\n",
    "    return tensor_batch\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 1 #each mini_batch has shape T, E \n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size = batch_size,\n",
    "    drop_last = True, \n",
    "    shuffle=False  # We handle randomness in the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------End of TSLA----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#only for sp500 dataset, detailed time info is not available for TSLA\n",
    "print(f\"unique values of 'Day': {sorted(data['Day'].unique())}; \\n num of 'Day': {len(data['Day'].unique())}\")\n",
    "print(f\"\\n unique values of 'Weekday': {sorted(data['Weekday'].unique())}; \\n num of 'Weekday': {len(data['Weekday'].unique())}\")\n",
    "print(f\"\\n unique values of 'Week': {sorted(data['Week'].unique())}; \\n num of 'Week': {len(data['Week'].unique())}\")\n",
    "print(f\"\\n unique values of 'Month': {sorted(data['Month'].unique())}; \\n num of 'Month': {len(data['Month'].unique())}\")\n",
    "print(f\"\\n unique values of 'Year': {sorted(data['Year'].unique())}; \\n num of 'Year': {len(data['Year'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#only select the data starting 2020 and afterward\n",
    "data = data[data[\"Year\"] >= 2020]\n",
    "print(f\"\\n unique values of 'Year': {sorted(data['Year'].unique())}; \\n num of 'Year': {len(data['Year'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#log the prices and the vol\n",
    "data.loc[:, [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]] = data.loc[:, [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].apply(np.log)\n",
    "print(f'check any inf after log: {data.loc[:, [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].apply(np.isinf).any().any()} \\n')\n",
    "print(f\"\\n {data.dtypes} \\n\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_plot = data.drop(columns = [\"Date\", \"Day\", \"Weekday\", \"Week\", \"Month\", \"Year\"], axis = 1)\n",
    "data_plot = data_plot.apply(lambda x: (x - x.mean())/x.std()) #global normalization only for visualization\n",
    "\n",
    "grid = sns.PairGrid(data_plot)\n",
    "grid.map_upper(sns.scatterplot)\n",
    "grid.map_lower(sns.kdeplot, fill=True)\n",
    "grid.map_diag(sns.histplot, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Determine the number of rows and columns for the subplot grid\n",
    "num_cols = len(data_plot.columns)\n",
    "num_rows = int(np.ceil(np.sqrt(num_cols)))\n",
    "num_cols_per_row = int(np.ceil(num_cols / num_rows))\n",
    "\n",
    "# Create subplots with the calculated layout\n",
    "fig, axes = plt.subplots(num_rows, num_cols_per_row, figsize=(15, 10)) \n",
    "\n",
    "# Iterate through columns and create boxplots\n",
    "axes = axes.flatten() # Flatten axes for easy iteration\n",
    "for i, column in enumerate(data_plot.columns):\n",
    "    ax = axes[i]\n",
    "    ax.boxplot(data[column])\n",
    "    ax.set_title(column)\n",
    "\n",
    "# Remove empty subplots (if any)\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***add the return columns for each real column***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#add log price returns\n",
    "# Step 1: Select numeric columns to compute differences\n",
    "numeric_cols = data.select_dtypes(include=['float64']).columns #prices are all in 'float'\n",
    "\n",
    "# Step 2: Calculate row-wise differences for numeric columns\n",
    "diff_df = data[numeric_cols].diff()\n",
    "\n",
    "# Step 3: Add differences to the original DataFrame (optional)\n",
    "# Prefix new columns with 'diff_'\n",
    "data[[f'diff_{col}' for col in numeric_cols]] = diff_df\n",
    "\n",
    "# Step 4: Print results\n",
    "print(\"DataFrame with differences:\\n\", data.head(5))\n",
    "\n",
    "# Step 5: Debug - Check for infinite or NaN values in differences\n",
    "#print(\"\\n Any infinite values in differences:\", data.isin([np.inf, -np.inf]).any().any())\n",
    "print(\"\\n Any infinite values in differences:\", data.drop(\"Date\", axis=1).apply(np.isinf).any().any())\n",
    "print(\"Any NaN values in differences:\", data.isna().any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***categorizing the calendar features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#turn the calendar features into category\n",
    "data.loc[:, [\"Day\", \"Weekday\", \"Week\", \"Month\", \"Year\"]] = data.loc[:, [\"Day\", \"Weekday\", \"Week\", \"Month\", \"Year\"]].astype(str).astype(\"category\")\n",
    "print(\"Updated data types:\\n\", data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***table of 1-day holding period return***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "d_hpr = data.drop(columns = ['Open', 'High', 'Low', 'Close', 'Volume'], axis = 1)\n",
    "d_hpr = d_hpr.dropna()\n",
    "\n",
    "print(f\"the shape of 1d_hpr is: {d_hpr.shape}\\n\")\n",
    "d_hpr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hpr_plot = d_hpr.drop(columns = [\"Date\", \"Day\", \"Weekday\", \"Week\", \"Month\", \"Year\"], axis = 1)\n",
    "\n",
    "grid = sns.PairGrid(hpr_plot)\n",
    "grid.map_upper(sns.scatterplot)\n",
    "grid.map_lower(sns.kdeplot, fill=True)\n",
    "grid.map_diag(sns.histplot, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Determine the number of rows and columns for the subplot grid\n",
    "num_cols = len(hpr_plot.columns)\n",
    "num_rows = int(np.ceil(np.sqrt(num_cols)))\n",
    "num_cols_per_row = int(np.ceil(num_cols / num_rows))\n",
    "\n",
    "# Create subplots with the calculated layout\n",
    "fig, axes = plt.subplots(num_rows, num_cols_per_row, figsize=(15, 10)) \n",
    "\n",
    "# Iterate through columns and create boxplots\n",
    "axes = axes.flatten() # Flatten axes for easy iteration\n",
    "for i, column in enumerate(hpr_plot.columns):\n",
    "    ax = axes[i]\n",
    "    ax.boxplot(d_hpr[column])\n",
    "    ax.set_title(column)\n",
    "\n",
    "# Remove empty subplots (if any)\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import EncoderNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss, MAE, MAPE, SMAPE #,PoissonLoss load at demand\n",
    "\n",
    "#from tensorboard import program #cannot call tensorboard from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#add extra real feature \"month_to_date_return\"\n",
    "# Step 1: Select numeric columns to compute differences\n",
    "numeric_cols = d_hpr.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# Step 2: Calculate row-wise cumulative sum for numeric columns\n",
    "mtd_diff_df = d_hpr.groupby([\"Month\",\"Year\"], observed = True)[numeric_cols].cumsum()\n",
    "\n",
    "# Step 3: Add differences to the original DataFrame (optional)\n",
    "# Prefix new columns with 'mtd_'\n",
    "d_hpr[[f'mtd_{col}' for col in numeric_cols]] = mtd_diff_df\n",
    "\n",
    "# Step 4: Debug - Check for infinite or NaN values in month_to_date_return\n",
    "print(\"Any infinite values in differences:\", mtd_diff_df.apply(np.isinf).any().any())\n",
    "print(\"Any NaN values in differences:\", mtd_diff_df.isna().any().any())\n",
    "print(f\"\\n {d_hpr.head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add time index for TimeSeriesDataSet use\n",
    "d_hpr[\"time_idx\"] = range(len(d_hpr))\n",
    "#becasue of the non-business days, data[\"time_idx\"] = (data[\"date\"] - data[\"date\"].min()).dt.days will not create consecutive int with +1 step\n",
    "\n",
    "# add a dummy group idx for TimeSeriesDataSet use\n",
    "d_hpr[\"dummy_group\"] = 1\n",
    "\n",
    "print(f\"the max of time_idx: {d_hpr['time_idx'].min()}\")\n",
    "print(f\"the min of time_idx: {d_hpr['time_idx'].max()}\")\n",
    "print(f\"the length of time_idx: {len(d_hpr['time_idx'])}\")\n",
    "print(f\"the data type is : {d_hpr['time_idx'].dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Any infinite values in differences: {d_hpr.isin([np.inf, -np.inf]).any().any()}\")\n",
    "print(f\"Any NaN values in differences: {d_hpr.isna().any().any()} \\n\")\n",
    "print(f\"the prepared data for final processing {d_hpr.shape}: \\n {d_hpr.head(5)} \\n\")\n",
    "print(f\"the data statistics: \\n {d_hpr.describe()} \\n\")\n",
    "print(f\"the data types of each col: \\n {d_hpr.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***prepare dataloader for pyotrch-forecasting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#dataset slicing\n",
    "max_prediction_length = 5\n",
    "max_encoder_length = 20\n",
    "\n",
    "#training_cutoff = d_hpr[\"time_idx\"].max() - 251*2 #hide out the last 2 years for val and test\n",
    "#training_data = d_hpr[lambda x: x.time_idx < training_cutoff]\n",
    "#validation_data = d_hpr[lambda x: (x.time_idx >= training_cutoff) & (x.time_idx < training_cutoff + 251)]\n",
    "#test_data = d_hpr[lambda x: x.time_idx >= training_cutoff + 251]\n",
    "\n",
    "training_data = d_hpr[d_hpr[\"Year\"].isin([\"2020\", \"2021\", \"2022\"])]\n",
    "validation_data = d_hpr[d_hpr[\"Year\"].isin([\"2023\"])]\n",
    "test_data = d_hpr[d_hpr[\"Year\"].isin([\"2024\", \"2025\"])]\n",
    "\n",
    "print(f\"\"\"\n",
    "train data shape: {training_data.shape}\n",
    "val data shape: {validation_data.shape}\n",
    "test data shape: {test_data.shape}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Any infinite values in train data: {training_data.isin([np.inf, -np.inf]).any().any()}\")\n",
    "print(f\"Any infinite values in val data: {validation_data.isin([np.inf, -np.inf]).any().any()}\")\n",
    "print(f\"Any infinite values in test data: {test_data.isin([np.inf, -np.inf]).any().any()} \\n\")\n",
    "print(f\"Any NaN values in train data: {training_data.isna().any().any()}\")\n",
    "print(f\"Any NaN values in val data: {validation_data.isna().any().any()}\")\n",
    "print(f\"Any NaN values in test data: {test_data.isna().any().any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    training_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"diff_Close\",\n",
    "    group_ids=[\"dummy_group\"],\n",
    "    max_encoder_length = max_encoder_length,\n",
    "    max_prediction_length = max_prediction_length,\n",
    "    time_varying_known_categoricals = ['Day', 'Weekday', 'Week', 'Month'], #\"Year\" could cause issue, since it is not consistant over val, test dataset, \n",
    "    #it can be put in \"time_varying_unknown_categoricals\".  \n",
    "    time_varying_unknown_reals = [\"diff_Open\", \"diff_High\", \"diff_Low\", \"diff_Close\", \"diff_Volume\", \"mtd_diff_Open\", \"mtd_diff_High\", \"mtd_diff_Low\", \n",
    "                               \"mtd_diff_Close\", \"mtd_diff_Volume\"],\n",
    "    target_normalizer = EncoderNormalizer() #transformation=\"softplus\")\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training, \n",
    "    validation_data #keep the predict default = False to make all the data will be included by a sliding window\n",
    ")\n",
    "\n",
    "test = TimeSeriesDataSet.from_dataset(\n",
    "    training, \n",
    "    test_data\n",
    ")\n",
    "\n",
    "# create dataloaders\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train = False, #with the train = False, a encoder + prediction sized window will slide through the whole dataset\n",
    "    batch_size = 9999, #this arg actually controls the batch dimension of the dataset(number of batches), instead of the number of samples in each batch. \n",
    "    #and when it >> whole data length during the window sliding, it will automatically = len(dataset) - window size + 1, the total number of window can be fitted \n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train = False, batch_size = 9999\n",
    ")\n",
    "test_dataloader = test.to_dataloader(\n",
    "    train = False, batch_size = 9999\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***prepare pl trainer and model for hyperparameter tunning and model fitting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(666)\n",
    "\n",
    "lr_tune_logger = TensorBoardLogger(save_dir = \"\", version = \"lr\")  # logging results to the current pwd under dir \"lr\"\n",
    "lr_early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-4, patience=10, mode=\"min\"\n",
    ")\n",
    "\n",
    "#set up trainer for tunning\n",
    "lr_trainer = pl.Trainer(\n",
    "    accelerator = \"auto\",\n",
    "    devices = \"auto\",\n",
    "    gradient_clip_val = 0.1,\n",
    "    #fast_dev_run=True,  # comment in for debugging, only 1 training and 1 validation batch to run\n",
    "    callbacks=[lr_early_stop_callback],\n",
    "    logger = lr_tune_logger,  \n",
    ")\n",
    "\n",
    "#set up tft for tunning \n",
    "tft_tuner = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # dummy lr required for the following lr_finder initiation\n",
    "    learning_rate = 0.06,\n",
    "    hidden_size = 8,  # most important hyperparameter apart from learning rate\n",
    "    lstm_layers = 2, \n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size = 2,\n",
    "    dropout = 0.1,  # between 0.1 and 0.3 are good values\n",
    "    loss = QuantileLoss(),\n",
    "    reduce_on_plateau_patience = 100,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft_tuner.size() / 1e3:.3f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# learning rate optimization\n",
    "lr_tuner = Tuner(lr_trainer).lr_find(\n",
    "    tft_tuner,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader,\n",
    "    max_lr = 0.1,\n",
    "    min_lr = 1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {lr_tuner.suggestion()}\")\n",
    "fig = lr_tuner.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#set up trainer for training\n",
    "logger = TensorBoardLogger(save_dir = \"\", version = \"train\")  # logging results to the current pwd\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-4, patience=10, mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator = \"auto\",\n",
    "    devices = \"auto\",\n",
    "    gradient_clip_val = 0.1,\n",
    "    #fast_dev_run=True,  # comment in for debugging, only 1 training and 1 validation batch to run\n",
    "    callbacks=[early_stop_callback],\n",
    "    logger = logger,\n",
    ")\n",
    "\n",
    "#set up tft for taining\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate = lr_tuner.suggestion(),\n",
    "    hidden_size = 8,  # most important hyperparameter apart from learning rate\n",
    "    lstm_layers = 2, \n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size = 2,\n",
    "    dropout = 0.1,  # between 0.1 and 0.3 are good values\n",
    "    loss = QuantileLoss(),\n",
    "    #log_interval = 10, # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches \n",
    "    reduce_on_plateau_patience = 100,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.3f}k\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#open tensorboard to check the results, does not work on kaggle?\n",
    "tb = program.TensorBoard()\n",
    "tb.configure(argv=[None, '--logdir', 'lightning_logs', '--port', '6006'])\n",
    "print(\"TensorBoard running at http://localhost:6006/\")\n",
    "tb.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#load the best model according to the validation loss from training log\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#check the metrics on val_dataset\n",
    "trainer.validate(best_tft, dataloaders=val_dataloader)#, ckpt_path=best_model_path)\n",
    "#the \"ckpt_path\" argument is not necessary, but it is good practice to load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#exam outliers of MAPE\n",
    "val_results = best_tft.predict(val_dataloader, return_y = True)\n",
    "apes = torch.abs((val_results.output - val_results.y[0]) / val_results.y[0])\n",
    "apes.mean() #it is reasonable to suspect there is 0s in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.sum(val_results.y[0] == 0) #so there is 5 x 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"MAPE by metric function: {MAPE()(val_results.output, val_results.y[0])}\")\n",
    "#the reason of the val metric does not raise inf is, the function has logic designed to handle 0s by adding \"1e-8\" from the source code\n",
    "_apes = torch.abs((val_results.output - val_results.y[0]) / (1e-8 + val_results.y[0]))\n",
    "print(f\"MAPE by hands: {_apes.mean()}\") #proved the above statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#predict on test set\n",
    "test_pred_x_raw = best_tft.predict(test_dataloader, mode=\"raw\", return_x=True, return_y=True)\n",
    "test_pred = test_pred_x_raw#.cpu() #move the results from GPU back to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#evaluation on test set\n",
    "trainer.test(best_tft, dataloaders=test_dataloader)#, ckpt_path=best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_time_idx = test_pred.x[\"decoder_time_idx\"].reshape(-1, 1)\n",
    "pred = test_pred.output.prediction.reshape(-1, 7)\n",
    "pred = torch.cat((pred_time_idx, pred), dim=1) #add the time index of the predictions as col=0 for solving the overlap time idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#prediction vs actual plotting function\n",
    "def plot_single_timeseries_quantile_predictions(tensor1_preds, tensor2_actuals,\n",
    "                                                quantile_levels=None, quantile_labels=None,\n",
    "                                                title=\"Time Series Quantile Prediction\"):\n",
    "    \"\"\"\n",
    "    Plots quantile predictions (tensor1_preds) against actual values (tensor2_actuals)\n",
    "    for a single time series.\n",
    "\n",
    "    Args:\n",
    "        tensor1_preds (np.ndarray): Quantile predictions. Shape: [time, features].\n",
    "                                    Features are assumed to be sorted quantiles.\n",
    "                                    Example for 7 features: [q0.02, q0.1, q0.25, q0.5, q0.75, q0.9, q0.98]\n",
    "        tensor2_actuals (np.ndarray): Actual values. Shape: [time].\n",
    "        quantile_levels (list of float, optional): The actual quantile levels corresponding\n",
    "                                                   to the features in tensor1_preds.\n",
    "                                                   Used for generating accurate default labels.\n",
    "        quantile_labels (list of str, optional): Labels for the prediction intervals.\n",
    "                                                 If None, default labels will be generated.\n",
    "                                                 Order should correspond to outermost to innermost interval.\n",
    "        title (str, optional): The title for the plot.\n",
    "    \"\"\"\n",
    "    if tensor1_preds.ndim != 2:\n",
    "        raise ValueError(\"tensor1_preds (predictions) must be 2D [time, features].\")\n",
    "    if tensor2_actuals.ndim != 1:\n",
    "        raise ValueError(\"tensor2_actuals (actuals) must be 1D [time].\")\n",
    "    if tensor1_preds.shape[0] != tensor2_actuals.shape[0]:\n",
    "        raise ValueError(\"Time dimension of tensor1_preds and tensor2_actuals must match.\")\n",
    "\n",
    "    num_time_steps = tensor1_preds.shape[0]\n",
    "    num_features = tensor1_preds.shape[1]\n",
    "\n",
    "    if num_features % 2 == 0:\n",
    "        raise ValueError(\"Number of features in tensor1_preds must be odd to have a central median.\")\n",
    "    \n",
    "    median_index = num_features // 2\n",
    "\n",
    "    # Define quantile labels if not provided\n",
    "    if quantile_labels is None:\n",
    "        if num_features == 7 and quantile_levels and len(quantile_levels) == 7:\n",
    "            # Generate labels based on provided quantile_levels\n",
    "            # Assumes pairs are (0,6), (1,5), (2,4) for features\n",
    "            pi1_lower, pi1_upper = quantile_levels[0], quantile_levels[6]\n",
    "            pi2_lower, pi2_upper = quantile_levels[1], quantile_levels[5]\n",
    "            pi3_lower, pi3_upper = quantile_levels[2], quantile_levels[4]\n",
    "            \n",
    "            quantile_labels = [\n",
    "                f\"{(pi1_upper - pi1_lower) * 100:.0f}% PI ({pi1_lower:.2f}-{pi1_upper:.2f})\", # Outermost\n",
    "                f\"{(pi2_upper - pi2_lower) * 100:.0f}% PI ({pi2_lower:.2f}-{pi2_upper:.2f})\", # Middle\n",
    "                f\"{(pi3_upper - pi3_lower) * 100:.0f}% PI ({pi3_lower:.2f}-{pi3_upper:.2f})\"  # Innermost\n",
    "            ]\n",
    "        elif num_features == 7: # Default for 7 features if specific levels not given\n",
    "             quantile_labels = [\"96% PI (e.g., 0.02-0.98)\", \"80% PI (e.g., 0.1-0.9)\", \"50% PI (e.g., 0.25-0.75)\"]\n",
    "        else:\n",
    "            # Fallback for a different number of features\n",
    "            quantile_labels = [f\"Interval {i+1}\" for i in range(num_features // 2)]\n",
    "    \n",
    "    if len(quantile_labels) != num_features // 2:\n",
    "        raise ValueError(f\"Expected {num_features // 2} quantile labels, but got {len(quantile_labels)}.\")\n",
    "\n",
    "    # Set a nice seaborn style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6)) # Single plot\n",
    "\n",
    "    time_indices = np.arange(num_time_steps)\n",
    "\n",
    "    # Plot actual values\n",
    "    ax.plot(time_indices, tensor2_actuals, label=\"Actual\", color=\"black\", linestyle='-', zorder=num_features//2 + 2)\n",
    "\n",
    "    # Plot median prediction (middle feature)\n",
    "    median_prediction = tensor1_preds[:, median_index]\n",
    "    median_label_text = f\"Median ({quantile_levels[median_index]:.2f}Q)\" if quantile_levels and median_index < len(quantile_levels) else \"Median Prediction\"\n",
    "    ax.plot(time_indices, median_prediction, label=median_label_text, color=\"blue\", marker='x', linestyle='--', zorder=num_features//2 + 1)\n",
    "\n",
    "    # Plot prediction intervals\n",
    "    # Intervals are formed by pairing features from outside in\n",
    "    # e.g., for 7 features: (feature 0, feature 6), (feature 1, feature 5), (feature 2, feature 4)\n",
    "    # Colors for intervals - from lighter to darker for better visual hierarchy\n",
    "    # Using a list of distinct, visually pleasing colors for intervals\n",
    "    interval_palette = sns.color_palette(\"Blues\", n_colors=num_features // 2 + 2) # Get a few shades\n",
    "    \n",
    "    # The quantile_labels should be ordered from outermost to innermost.\n",
    "    # The loop for j goes from 0 (outermost interval) to (num_features // 2 - 1) (innermost interval).\n",
    "    for j in range(num_features // 2):\n",
    "        lower_quantile_idx = j\n",
    "        upper_quantile_idx = num_features - 1 - j\n",
    "        \n",
    "        # Assign colors such that the widest interval is lightest, narrowest is darkest within the theme\n",
    "        # So, interval_colors[j] means the j-th interval (0 = outermost) gets a progressively darker shade.\n",
    "        # The label quantile_labels[j] should correspond to this j-th interval.\n",
    "        ax.fill_between(time_indices, tensor1_preds[:, lower_quantile_idx], tensor1_preds[:, upper_quantile_idx],\n",
    "                        color=interval_palette[j], # interval_palette[0] is light, interval_palette[num_features//2 -1] is darker\n",
    "                        alpha=0.3 + (j * 0.1), # Alpha can also increase for inner bands if desired\n",
    "                        label=quantile_labels[j], \n",
    "                        zorder=j+1)\n",
    "\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time Step\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "    if num_time_steps <= 20: # Show markers if not too many time steps\n",
    "        ax.set_xticks(time_indices)\n",
    "    else: # Otherwise, let matplotlib decide tick locations for readability\n",
    "        pass\n",
    "\n",
    "    # Add legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # Custom sort order for legend: Actual, Median, then PIs (already ordered by plotting)\n",
    "    # If specific order is needed and not achieved by plotting order:\n",
    "    # order_preference = [\"Actual\", median_label_text] + quantile_labels\n",
    "    # sorted_legend = sorted(zip(handles, labels), key=lambda x: order_preference.index(x[1]) if x[1] in order_preference else float('inf'))\n",
    "    # handles = [h for h, l in sorted_legend]\n",
    "    # labels = [l for h, l in sorted_legend]\n",
    "    ax.legend(handles, labels, loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for the legend outside\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#create a function to get the avg of the duplicate rows, because of the multihorizon prediciton having overlap of prediction time_idx\n",
    "def average_duplicate_rows(tensor, column_index):\n",
    "    \"\"\"\n",
    "    Calculates the average of other columns for duplicate rows based on values in a specified column.\n",
    "\n",
    "    Args:\n",
    "        tensor: A 2D PyTorch tensor.\n",
    "        column_index: The index of the column used for identifying duplicate rows.\n",
    "\n",
    "    Returns:\n",
    "        A new tensor with averaged rows.\n",
    "    \"\"\"\n",
    "\n",
    "    if tensor.ndim != 2:\n",
    "      raise ValueError(\"Input tensor must be 2D.\")\n",
    "    \n",
    "    if column_index >= tensor.shape[1]:\n",
    "        raise IndexError(\"column_index out of range\")\n",
    "    \n",
    "    # Convert to NumPy array for easier manipulation\n",
    "    tensor_np = tensor.numpy()\n",
    "\n",
    "    # Get unique values in the specified column and their indices\n",
    "    unique_values, inverse_indices = torch.unique(tensor[:, column_index], return_inverse=True)\n",
    "    unique_values = unique_values.numpy()\n",
    "    inverse_indices = inverse_indices.numpy()\n",
    "\n",
    "    # Create a dictionary to store rows for each unique value\n",
    "    grouped_rows = {}\n",
    "    for i, val in enumerate(inverse_indices):\n",
    "        if val not in grouped_rows:\n",
    "          grouped_rows[val] = []\n",
    "        grouped_rows[val].append(tensor_np[i])\n",
    "\n",
    "    # Calculate the average of other columns for each group\n",
    "    averaged_rows = []\n",
    "    for _, rows in grouped_rows.items():\n",
    "        rows = torch.tensor(rows) #convert list of rows to tensor\n",
    "        averaged_row = rows.mean(dim=0)\n",
    "        averaged_rows.append(averaged_row)\n",
    "    \n",
    "    averaged_rows = torch.stack(averaged_rows)\n",
    "\n",
    "    return averaged_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred = average_duplicate_rows(pred, 0) #by somehow the \"test_pred_x_raw\" is not shown on GPU, but the post processing \"pred\" is on GPU?\n",
    "test_plot = torch.tensor(test_data[test_data[\"time_idx\"] >= pred[0,0].numpy()][\"diff_Close\"].values)\n",
    "pred_plot = pred[:, 1:] #remove the extra time idx from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Define Quantile Labels based on SPECIFIC_QUANTILE_LEVELS ---\n",
    "# These labels will be passed to the plotting function.\n",
    "SPECIFIC_QUANTILE_LEVELS= [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98] # The quantile levels used in the model\n",
    "\n",
    "# The function can also generate them if quantile_levels are passed.\n",
    "# Order: Outermost, Middle, Innermost\n",
    "pi_outer_label = f\"{(SPECIFIC_QUANTILE_LEVELS[6] - SPECIFIC_QUANTILE_LEVELS[0])*100:.0f}% PI ({SPECIFIC_QUANTILE_LEVELS[0]:.2f}-{SPECIFIC_QUANTILE_LEVELS[6]:.2f})\"\n",
    "pi_mid_label = f\"{(SPECIFIC_QUANTILE_LEVELS[5] - SPECIFIC_QUANTILE_LEVELS[1])*100:.0f}% PI ({SPECIFIC_QUANTILE_LEVELS[1]:.2f}-{SPECIFIC_QUANTILE_LEVELS[5]:.2f})\"\n",
    "pi_inner_label = f\"{(SPECIFIC_QUANTILE_LEVELS[4] - SPECIFIC_QUANTILE_LEVELS[2])*100:.0f}% PI ({SPECIFIC_QUANTILE_LEVELS[2]:.2f}-{SPECIFIC_QUANTILE_LEVELS[4]:.2f})\"\n",
    "    \n",
    "# The order in custom_labels MUST match the order of plotting fill_between\n",
    "# which is from outermost to innermost (j=0 to num_features//2 - 1)\n",
    "custom_interval_labels = [pi_outer_label, pi_mid_label, pi_inner_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Plot the pred_return v true_return ---\n",
    "print(f\"Tensor1 (predictions) shape: {pred_plot.shape}\")\n",
    "print(f\"Tensor2 (actuals) shape: {test_plot.shape}\")\n",
    "print(f\"Quantile levels being plotted: {SPECIFIC_QUANTILE_LEVELS}\")\n",
    "\n",
    "plot_single_timeseries_quantile_predictions(\n",
    "    pred_plot,\n",
    "    test_plot,\n",
    "    quantile_levels=SPECIFIC_QUANTILE_LEVELS,\n",
    "    quantile_labels=custom_interval_labels, # Pass the correctly ordered labels\n",
    "    title=\"log Return Prediction with Quantiles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#plot log close predictions, since the target = \"diff_Close\"\n",
    "#the true log price from test set\n",
    "test_date = test_data[test_data[\"time_idx\"] >= (pred[0,0]-1).numpy()][[\"Date\", \"time_idx\"]] #find the \"time_idx\" corresponding \"Date\" to slice the respective \"Close\" price\n",
    "#get the extra t_-1 price for the 1st prediction price calculation\n",
    "\n",
    "test_price = data[data[\"Date\"].isin(test_date.Date)][\"Close\"] \n",
    "test_price = torch.tensor(test_price.values)\n",
    "test_price = test_price.reshape(test_price.shape[0], 1) #to match the 'pred' shape for broadcasting operation\n",
    "\n",
    "#construct prediciton log price by logP_t + pred_logR_t = logP_t+1\n",
    "pred_price = test_price[:test_price.shape[0]-1,] + pred[...,1:]\n",
    "\n",
    "test_price_plot = test_price[1:,].squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Plot the pred_price v true_price ---\n",
    "print(f\"Tensor1 (predictions) shape: {pred_price.shape}\")\n",
    "print(f\"Tensor2 (actuals) shape: {test_price_plot.shape}\")\n",
    "print(f\"Quantile levels being plotted: {SPECIFIC_QUANTILE_LEVELS}\")\n",
    "\n",
    "plot_single_timeseries_quantile_predictions(\n",
    "    pred_price,\n",
    "    test_price_plot,\n",
    "    quantile_levels=SPECIFIC_QUANTILE_LEVELS,\n",
    "    quantile_labels=custom_interval_labels, # Pass the correctly ordered labels\n",
    "    title=\"log Price Prediction with Quantiles\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7076136,
     "sourceId": 12500687,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
